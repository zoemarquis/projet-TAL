{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "--co-HHyteh0",
        "Mp_4ieadteii"
      ]
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-MYbGvEtehY"
      },
      "source": [
        "# Imports n√©cessaires\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "# Suppression de l'affichage des messages d'avertissement\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import string\n",
        "import time\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn import metrics\n",
        "from sklearn import model_selection\n",
        "from sklearn import set_config\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import FunctionTransformer, MinMaxScaler\n",
        "from sklearn.pipeline import Pipeline, FeatureUnion, make_pipeline\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import spacy\n",
        "import nltk\n",
        "\n",
        "# Pour √©viter l'affichage tronqu√© des descriptions\n",
        "pd.set_option('display.max_colwidth', -1)\n",
        "# Pour la visualisation des pipelines sklearn\n",
        "set_config(display='diagram')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xoq3snqmtehd"
      },
      "source": [
        "# Classification de documents\n",
        "\n",
        "<div class=\"alert alert-block alert-info\">\n",
        "\n",
        "ü•Ö **Objectifs**\n",
        "\n",
        "- Savoir utiliser `scikit-learn` pour faire de l'apprentissage supervis√© √† partir de documents\n",
        "- Savoir pr√©traiter les donn√©es pour l'apprentissage\n",
        "- R√©aliser une validation crois√©e pour l'apprentissage\n",
        "- Interpr√©ter les r√©sultats obtenus\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVFF-1SVtehg"
      },
      "source": [
        "## 1. Donn√©es\n",
        "\n",
        "Nous allons travailler avec un jeu de donn√©es contenant des descriptions de vins fran√ßais, t√©l√©charg√©es √† l'adresse suivante : https://www.kaggle.com/zynicide/wine-reviews/\n",
        "Ces descriptions proviennent du site WineEnthusiast, et comprennent par ailleurs le prix d'une bouteille de vin en dollars, la r√©gion d'o√π est issu le vin et la vari√©t√© de raisin utilis√©e.  \n",
        "\n",
        "L'objectif sera de parvenir √† pr√©dire automatiquement la r√©gion, en fonction des autres informations.\n",
        "\n",
        "Nous allons commencer par r√©cup√©rer et charger les donn√©es :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2meZytW9tjZy"
      },
      "source": [
        "# Cr√©ation d'un dossier appel√© data\n",
        "!mkdir data\n",
        "# T√©l√©chargement du fichier winemag-fr.csv dans le dossier data\n",
        "!wget -P data https://git.unistra.fr/dbernhard/ftaa_data/-/raw/main/winemag-fr.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vioXuXljtehh"
      },
      "source": [
        "# Lecture du fichier CSV\n",
        "wine_df = pd.read_csv(\"data/winemag-fr.csv\", sep=\",\", dtype={'description': 'object',\n",
        "                                           'price': 'float64',\n",
        "                                           'province': 'category',\n",
        "                                           'variety': 'object'})\n",
        "# Nettoyage des donn√©es\n",
        "# - Suppression des lignes comportant des donn√©es manquantes (dropna)\n",
        "# - Suppression des doublons (drop_duplicates)\n",
        "wine_df = wine_df.drop_duplicates().dropna(how = 'any')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHJTlEhGtehj"
      },
      "source": [
        "wine_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "heByQmvWtehk"
      },
      "source": [
        "Le jeu de donn√©es contient 10 166 lignes. Ce jeu de donn√©es est relativement petit pour l'apprentissage automatique. Les colonnes `description` et `variety` contiennent du texte. La colonne `price` des nombres r√©els. La colonne `province` est cat√©gorielle : elle ne peut prendre qu'un nombre fini de valeurs diff√©rentes (modalit√©s)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0cSVx9stehk"
      },
      "source": [
        "Nous allons ajouter deux nouvelles colonnes :\n",
        "- `sparkling` (colonne bool√©enne pour les vins p√©tillants)\n",
        "- `expensive` (colonne bool√©enne pour les vins chers / peu chers). Cette op√©ration consiste √† **discr√©tiser** la colonne `price`, c'est-√†-dire transformer des variables continues en\n",
        "valeurs discr√®tes. Cela peut dans certains cas am√©liorer les r√©sultats de\n",
        "l‚Äôapprentissage, faciliter l‚Äôinterpr√©tation des r√©sultats et r√©duire le temps de calcul. Nous allons classer les vins  en deux cat√©gories : *cher* / *peu cher*, en utilisant un seuil de prix de 50."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4dwYLWStehm"
      },
      "source": [
        "A partir de cette valeur, nous d√©finissons la colonne bool√©enne `expensive`, dont la valeur sera 1 si le prix est sup√©rieur au prix de 50, 0 dans le cas contraire :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJ6qzgeytehn"
      },
      "source": [
        "threshold_price = 50\n",
        "wine_df['expensive'] = wine_df['price'].map(lambda x : 1 if x > threshold_price else 0)\n",
        "wine_df['expensive'] = wine_df['expensive'].astype('int64')\n",
        "wine_df.expensive.value_counts().plot(kind='bar')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9Cxl1H_teho"
      },
      "source": [
        "De la m√™me mani√®re, nous d√©finissons la colonne bool√©enne `sparkling`, dont la valeur sera 1 si le vin est p√©tillant, 0 dans le cas contraire :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7V3moEW8tehp"
      },
      "source": [
        "wine_df['sparkling'] = wine_df['variety'].map(\n",
        "    lambda v : 1 if v in ['Champagne_Blend', 'Sparkling_Blend'] else 0)\n",
        "wine_df['sparkling'] = wine_df['sparkling'].astype('int64')\n",
        "wine_df.sparkling.value_counts().plot(kind='bar')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pd7S6y88tehp"
      },
      "source": [
        "## 2.  Apprentissage de la r√©gion\n",
        "\n",
        "Nous allons tout d'abord tenter d'apprendre la r√©gion, √† partir du type p√©tillant ou non, de la cat√©gorie de prix, de la description et de la vari√©t√© de raisin.\n",
        "\n",
        "Les diff√©rentes r√©gions pr√©sentes dans le jeu de donn√©es sont les suivantes :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgvOWLUFtehp"
      },
      "source": [
        "wine_df.province.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "na6UkpnBtehq"
      },
      "source": [
        "Par convention, en science des donn√©es :\n",
        "- **`X`** est utilis√© pour les donn√©es sources utilis√©es pour l'apprentissage, c'est √† dire l'ensemble des traits ou caract√©ristiques (*features*)\n",
        "- **`y`**  est utilis√© pour ce que l'on cherche √† pr√©dire (la ou les classes, en cas de classification multi-label)\n",
        "- **`train`** est utilis√© pour les donn√©es d'apprentissage\n",
        "- **`test`** est utilis√© pour les donn√©es d'√©valuation\n",
        "\n",
        "Nous allons tout d'abord extraire `X` et `y` √† partir de nos donn√©es :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dadmhrGOtehq"
      },
      "source": [
        "# Les colonnes contenant les informations utilis√©es pour l'apprentissage\n",
        "X = wine_df[['sparkling', 'expensive', 'description', 'variety']]\n",
        "# La colonne contenant l'information √† pr√©dire\n",
        "y = wine_df.province"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGKaxHDRtehr"
      },
      "source": [
        "X.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9fw7joUtehr"
      },
      "source": [
        "y.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPhM5571tehs"
      },
      "source": [
        "Pour r√©aliser nos premi√®res exp√©riences, nous allons d√©couper automatiquement les donn√©es en jeu d'apprentissage et de validation (_dev-test set_).\n",
        "\n",
        "Nous allons uiliser 20% des donn√©es pour la validation (`test_size=0.2`). Avant d√©coupage, les donn√©es seront m√©lang√©es (`shuffle=True`). Cette op√©ration est contr√¥l√©e par un entier (`random_state=12`) qui permet de contr√¥ler le g√©n√©rateur de nombre al√©atoire et ainsi s'assurer que les donn√©es seront d√©coup√©es de la m√™me mani√®re √† chaque appel de la fonction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uABIfy0ltehs"
      },
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2,\n",
        "                                                    random_state=12, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTVJwqg7tehs"
      },
      "source": [
        "### 2.1. Cr√©ation de pipelines\n",
        "    \n",
        "Dans `scikit-learn` on dispose de diff√©rents types d'outils :    \n",
        "- **Estimateurs** :\n",
        "    - Objectif : estimer certains param√®tres √† partir d‚Äôun jeu de donn√©es, apprendre un mod√®le\n",
        "    - L‚Äôestimation est effectu√©e par appel √† la m√©thode `fit()`\n",
        "    - Exemple : m√©thode `fit()` de `CountVectorizer`\n",
        "- **Transformateurs** :\n",
        "    - Objectif : transformer le jeu de donn√©es\n",
        "    - La transformation est effectu√©e par appel √† la m√©thode `transform()`\n",
        "    - La transformation repose en g√©n√©ral sur les param√®tres appris √† la phase d'estimation\n",
        "- **Pr√©dicteurs**\n",
        "    - Certains estimateurs peuvent faire des pr√©dictions √† partir d'un jeu de donn√©es\n",
        "    - La pr√©diction se fait par appel √† la m√©thode `predict()`\n",
        "    - Elle renvoie les pr√©dictions √† partir d'un nouveau jeu de donn√©es\n",
        "- **Pipeline**\n",
        "    - S√©quence de transformateurs (`fit` et `transform`) et de pr√©dicteurs (`fit` et `predict`)\n",
        "\n",
        "Nous allons d√©crire une cha√Æne de traitement sp√©cifique √† chaque type de colonne. En particulier, les colonnes correspondant √† des textes dans `X` doivent √™tre transform√©es en nombres (sac de mots) pour pouvoir √™tre utilis√©es pour l'apprentissage (colonnes `description`, `variety`).\n",
        "\n",
        "Ces cha√Ænes de traitement seront d√©crites dans des objets de type `Pipeline` qui incluent toutes les √©tapes de pr√©-traitement et de classification. L'utilisation des objets `Pipeline` rend le code plus flexible, mieux structur√©, et permet l'utilisation plus ais√©e de la validation crois√©e."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIZbJACBteht"
      },
      "source": [
        "#### 2.1.1. Colonne `variety`\n",
        "\n",
        "Dans cette colonne, lorsque le nom de la vari√©t√© comporte plusieurs mots, comme \"Bordeaux-style\\_Red\\_Blend\", les mots sont s√©par√©s par `_`. Nous allons donc d√©finir une fonction de tok√©nisation qui d√©coupe la vari√©t√© en fonction de ce signe. Cette fonction de tok√©nisation sera ensuite utilis√©e par un objet de type `CountVectorizer`, afin de pouvoir passer √† une repr√©sentation \"sac de mots\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YRYMWFgteht"
      },
      "source": [
        "# Fonction de tok√©nisation\n",
        "def tokenize_variety(text):\n",
        "    return text.split('_')\n",
        "\n",
        "# Objet CountVectorizer pour la transformation en sac de mots\n",
        "var_vectorizer = CountVectorizer(tokenizer=tokenize_variety,\n",
        "                                 min_df=0.01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2leFOOqAteht"
      },
      "source": [
        "Exemple d'utilisation de `var_vectorizer` sur les 5 premi√®res lignes de `X_val` :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJSnGucbtehu"
      },
      "source": [
        "res_var = var_vectorizer.fit_transform(X_val.variety.head())\n",
        "print(\"Input varieties\")\n",
        "print(X_val.variety.head())\n",
        "print()\n",
        "print(\"Output bag of words\")\n",
        "var_bow = pd.DataFrame(res_var.toarray(), columns=var_vectorizer.get_feature_names_out())\n",
        "var_bow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcH1uATqtehu"
      },
      "source": [
        "üö® Les r√©ponses aux questions doivent √™tre donn√©es sur Moodle (Questionnaire \"R√©ponses aux questions du TP\")\n",
        "\n",
        "<div class=\"alert alert-info\">\n",
        "\n",
        "‚ùì [1] Que constatez-vous concernant la casse des caract√®res ? Que fait <code>CountVectorizer</code> par d√©faut ?\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3rbUwKZtehv"
      },
      "source": [
        "<div class=\"alert alert-info\">\n",
        "\n",
        "‚ùì [2] A quoi correspond le param√®tre <code>min_df</code> utilis√© √† l'initialisation de <code>var_vectorizer</code> ? Vous pouvez consulter l'aide de CountVectorizer pour r√©pondre √† la question : https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdymSYWwtehv"
      },
      "source": [
        "#### 2.1.2. Colonne `description`\n",
        "\n",
        "Pour la colonne `description`, le texte sera d√©coup√© en mots √† l'aide de la fonction `split_into_tokens_nltk`. Les mots seront √©galement mis en minuscules et les mots vides seront supprim√©s, √† l'aide des param√®tres sp√©cifiques √† `TfidfVectorizer` :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P06nk_TXufT-"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GcLhk0xtehw"
      },
      "source": [
        "def split_into_tokens_nltk(desc) :\n",
        "    return word_tokenize(desc)\n",
        "\n",
        "# Liste des mots vides de NLTK + signes de ponctuation\n",
        "nltk_stopwords = stopwords.words('english')+list(string.punctuation)\n",
        "\n",
        "# Objet TfidfVectorizer\n",
        "desc_vectorizer = TfidfVectorizer(tokenizer=split_into_tokens_nltk,\n",
        "                                  lowercase=True,\n",
        "                                  stop_words=nltk_stopwords,\n",
        "                                  min_df=0.01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhqyLwCstehw"
      },
      "source": [
        "Exemple d'utilisation de `desc_vectorizer` sur les 5 premi√®res lignes de `X_val` :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhkCgc_ctehw"
      },
      "source": [
        "res_desc = desc_vectorizer.fit_transform(X_val.description.head())\n",
        "print(\"Input descriptions\")\n",
        "print(X_val.description.head())\n",
        "print()\n",
        "print(\"Output bag of words\")\n",
        "desc_bow = pd.DataFrame(res_desc.toarray(), columns=desc_vectorizer.get_feature_names_out())\n",
        "desc_bow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9zaTF25tehx"
      },
      "source": [
        "#### 2.1.3 Utilisation de la colonne `description` pour obtenir des informations statistiques\n",
        "\n",
        "Nous pouvons d√©duire des informations suppl√©mentaires √† partir de la description : sa longueur en nombre de caract√®res et le nombre approximatif de phrases (en comptant le nombre de points).\n",
        "Pour ce faire, nous allons d√©finir une function particuli√®re charg√©e de calculer ces informations, `text_stats`. Ces informations seront ensuite transform√©es en traits utilisables pour l'apprentissage √† l'aide d'un objet de type `DictVectorizer` (cf. https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.DictVectorizer.html) :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YaB-VRoitehx"
      },
      "source": [
        "# Source : https://scikit-learn.org/stable/auto_examples/compose/plot_column_transformer.html\n",
        "def text_stats(descriptions):\n",
        "    return [{\"length\": len(text), \"num_sentences\": text.count(\".\")}\n",
        "            for text in descriptions]\n",
        "\n",
        "text_stats_transformer = FunctionTransformer(text_stats)\n",
        "text_stats_vectorizer = DictVectorizer(sparse=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5-hXrb1tehy"
      },
      "source": [
        "Exemple d'utilisation de `text_stats_transformer` sur les 5 premi√®res lignes de `X_val` :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1fPLml_tehy"
      },
      "source": [
        "res_dict = text_stats_transformer.transform(X_val.description.head())\n",
        "res_stats = text_stats_vectorizer.fit_transform(res_dict)\n",
        "print(\"Input descriptions\")\n",
        "print(X_val.description.head())\n",
        "print()\n",
        "print(\"Output statistics\")\n",
        "stats = pd.DataFrame(res_stats, columns=text_stats_vectorizer.get_feature_names_out())\n",
        "stats"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smNLmn8Etehy"
      },
      "source": [
        "On constate que ces mesures sont bien sup√©rieures √† 1. Les variables `length` et `num_sentences` ont des √©chelles de valeurs tr√®s diff√©rentes des variables obtenues par `CountVectorizer` et `TfIdfVectorizer`, qui sont comprises entre 0 et 1. Cela peut affecter la classification en donnant artificiellement plus de poids aux variables `length` et `num_sentences`. Pour cela, on peut normaliser les donn√©es, afin d'obtenir des plages de valeurs comparables pour les diff√©rentes variables. Plusieurs m√©thodes existent (standardisation √† l'aide du z-score : moyenne nulle et variance de 1, par la valeur maximum absolue, etc.). Nous allons utiliser `MinMaxScaler` (cf. https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html#sklearn.preprocessing.MinMaxScaler). Cela permet d'obtenir des valeurs comprises dans un intervalle donn√©, par exemple \\[0, 1\\] :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6x0oUIetehz"
      },
      "source": [
        "min_max_scaler = MinMaxScaler()\n",
        "scaled_stats = min_max_scaler.fit_transform(res_stats)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lP3fqOgTtehz"
      },
      "source": [
        "print(\"Before MinMax scaling\")\n",
        "print(res_stats)\n",
        "print()\n",
        "print(\"After MinMax scaling\")\n",
        "print(scaled_stats)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bawg-BaUtehz"
      },
      "source": [
        "<div class=\"alert alert-info\">\n",
        "\n",
        "‚ùì [3] Que deviennent les valeurs minimum et maximum apr√®s la normalisation ?\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--co-HHyteh0"
      },
      "source": [
        "#### 2.1.4. Colonnes `expensive` et `sparkling`\n",
        "\n",
        "Ces colonnes ne contiennent que des 0 et des 1 et peuvent donc √™tre utilis√©es telles quelles, sans n√©cessiter de traitement particulier."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aERhvlr5teh0"
      },
      "source": [
        "#### 2.1.5.  Cha√Æne de pr√©-traitement compl√®te\n",
        "\n",
        "Il est maintenant possible de combiner toutes ces cha√Ænes de pr√©-traitement afin d'obtenir une cha√Æne globale, qui produira l'union des traits g√©n√©r√©s ind√©pendamment par chaque type de pr√©-traitement op√©r√© sur les colonnes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlE8y3e1teh0"
      },
      "source": [
        "column_trans = ColumnTransformer(\n",
        "     [\n",
        "         # Colonne 'variety' : bag-of-words\n",
        "         ('variety_bow', var_vectorizer, 'variety'),\n",
        "         # Colonne 'description' : tf-idf\n",
        "         ('description_tfidf', desc_vectorizer, 'description'),\n",
        "         # Colonne 'description' : statistiques\n",
        "         (\n",
        "             'description_stats',\n",
        "             Pipeline(\n",
        "                 [\n",
        "                     ('text_stats', text_stats_transformer),\n",
        "                     ('vect', text_stats_vectorizer),\n",
        "                     ('scaling', min_max_scaler)\n",
        "                 ]\n",
        "             ),\n",
        "             'description'\n",
        "         )\n",
        "     ],\n",
        "     # Colonnes 'expensive' et 'sparkling' : conserv√©es telles quelles\n",
        "     remainder='passthrough'\n",
        " )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVJgqDULteh0"
      },
      "source": [
        "Visualisation de la cha√Æne de pr√©-traitement compl√®te :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBd2sQmateh1"
      },
      "source": [
        "column_trans"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yaNj_zAteh1"
      },
      "source": [
        "### 2.2. Apprentissage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "toqegPiSteh1"
      },
      "source": [
        "On peut maintenant effectuer une cha√Æne compl√®te, apprentissage compris. L'algorithme d'apprentissage utilis√© ici est `LogisticRegression()` :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHMRgpbhteh1"
      },
      "source": [
        "# Pr√©traitement + apprentissage\n",
        "classifier_pipeline = make_pipeline(\n",
        "    # Pr√©paration des donn√©es pour l'apprentissage\n",
        "    column_trans,\n",
        "    # Algorithme d'apprentissage\n",
        "    LogisticRegression()\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIr9Hdj6teh2"
      },
      "source": [
        "# Apprentissage avec les donn√©es d'entra√Ænement\n",
        "classifier_pipeline.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "144wYAUPteh2"
      },
      "source": [
        "Nous allons ensuite √©valuer le mod√®le sur les donn√©es de test :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cgIxr3Zteh3"
      },
      "source": [
        "y_pred = classifier_pipeline.predict(X_val)\n",
        "print(\"Classification report:\\n\\n{}\".format(classification_report(y_val, y_pred)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNsILZWwteh3"
      },
      "source": [
        "Dans l'affichage des r√©sultats, la colonne `support` correspond au nombre d'instances de chaque classe dans les donn√©es de test (classes r√©elles et non pas classes pr√©dites par le classifieur).\n",
        "\n",
        "(voir https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmhVUTJRteh3"
      },
      "source": [
        "<div class=\"alert alert-info\">\n",
        "\n",
        "‚ùì [4] Quel est le score de justesse ?\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6L-E26Vteh4"
      },
      "source": [
        "<div class=\"alert alert-info\">\n",
        "\n",
        "‚ùì [5] Quelles sont les r√©gions obtenant les meilleurs r√©sultats en termes de :\n",
        "    <ul>\n",
        "        <li>pr√©cision</li>\n",
        "        <li>rappel</li>\n",
        "        <li>f1-score (f-mesure)</li>\n",
        "    </ul>\n",
        "    \n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U54ZlHUIteh4"
      },
      "source": [
        "<div class=\"alert alert-info\">\n",
        "\n",
        "‚ùì [6] Quelle r√©gion a le plus grand support ?\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikq4s_vLteh4"
      },
      "source": [
        "### 2.3. Analyse des r√©sultats √† l'aide des matrices de confusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WJ4XKccteh4"
      },
      "source": [
        "Chaque ligne d'une matrice de confusion correspond √† la classe r√©elle (classe attendue) et chaque colonne correspond √† la classe pr√©dite. Si la classification √©tait parfaite, alors on ne trouverait que des valeurs non nulles sur la diagonale principale (coin sup√©rieur gauche vers coin inf√©rieur droit) et des valeurs nulles ailleurs dans la matrice (absence de confusions).\n",
        "\n",
        "La matrice de confusion permet de rep√©rer facilement les classes pour lesquelles le mod√®le √† le plus de difficult√©s (grandes valeurs qui ne se trouvent pas sur la diagonale) et avec quelle(s) autre(s) classe(s) ces classes sont le plus souvent confondues"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzvYIVoFteh5"
      },
      "source": [
        "# Liste des labels (classes) se trouvant dans les donn√©es de test\n",
        "labels = np.unique(y_val)\n",
        "# Matrice de confusion\n",
        "cm =  confusion_matrix(y_val, y_pred, labels=labels)\n",
        "# Matrice de confusion sous forme de DataFrame\n",
        "confusion_df = pd.DataFrame(cm, index=labels, columns=labels)\n",
        "print('confusion matrix\\n')\n",
        "print('(row=expected, col=predicted)')\n",
        "confusion_df.head(n=15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-Njv0xEteh5"
      },
      "source": [
        "<div class=\"alert alert-info\">\n",
        "\n",
        "‚ùì [7] Combien d'instances de la r√©gion 'Loire-Valley' sont correctement class√©es ?\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vmu7eGMLteh5"
      },
      "source": [
        "Affichage des r√©gions qui sont le plus fr√©quemment confondues avec 'Alsace' :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2oWnd9fteh6"
      },
      "source": [
        "confusion_df.loc['Alsace'].sort_values(ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8cB-U3fteh6"
      },
      "source": [
        "<div class=\"alert alert-info\">\n",
        "\n",
        "‚ùì [8] Quelles sont les 3 r√©gions de production des vins les plus fr√©quemment confondues avec l'Alsace ?\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPM-wTY7teh6"
      },
      "source": [
        "La matrice de confusion peut √©galement √™tre repr√©sent√©e sous forme graphique :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRmsaQisteh6"
      },
      "source": [
        "plt.matshow(confusion_matrix(y_val, y_pred),\n",
        "            cmap=plt.cm.binary, interpolation='nearest')\n",
        "plt.title('confusion matrix')\n",
        "plt.colorbar()\n",
        "plt.ylabel('expected label')\n",
        "plt.xlabel('predicted label')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-3GrymTteh7"
      },
      "source": [
        "Affichage en couleur avec nom des classes :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58JuWilGteh7"
      },
      "source": [
        "# Source : https://intellipaat.com/community/1611/sklearn-plot-confusion-matrix-with-labels\n",
        "# http://www.tarekatwan.com/index.php/2017/12/how-to-plot-a-confusion-matrix-in-python/\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "cax = ax.matshow(cm, interpolation='nearest', cmap=plt.cm.Oranges)\n",
        "fig.colorbar(cax)\n",
        "tick_marks = np.arange(len(labels))\n",
        "labels_for_fig = [l[0:5]+'.' for l in labels]\n",
        "plt.xticks(tick_marks, labels_for_fig, rotation=45)\n",
        "plt.yticks(tick_marks, labels_for_fig)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Expected')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IaeubHnLteh8"
      },
      "source": [
        "### 2.4. Apprentissage et √©valuation par validation crois√©e\n",
        "\n",
        "Rappel :       \n",
        "- Validation crois√©e √† $k$ plis ($k$_-fold cross-validation_) : les donn√©es d'entra√Ænement sont d√©coup√©es en $k$ parties (les \"plis\") :\n",
        "    - Un mod√®le est entra√Æn√© en utilisant $k$ - 1 \"plis\" puis valid√© sur le \"pli\" restant\n",
        "    - On fait ensuite la moyenne des mesures d'√©valuation pour obtenir la performance finale du mod√®le.\n",
        "- Cela permet d'√©viter de d√©couper les donn√©es disponibles en jeu d'entra√Ænement, de validation et de test : le jeu de validation n'est plus n√©cessaire\n",
        "\n",
        "#### 2.4.1. `KFold`\n",
        "\n",
        "`KFold` d√©coupe le jeu de donn√©es en $k$ plis cons√©cutifs (par d√©faut, les donn√©es ne sont pas m√©lang√©es : cela peut √™tre modifi√© √† l'aide du param√®tre `shuffle`)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ziYsRq6teh8"
      },
      "source": [
        "# Nombre de plis\n",
        "folds = 5\n",
        "# D√©coupage en plis\n",
        "kfold = model_selection.KFold(n_splits=folds, shuffle=True, random_state=12)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-vm_4gzteh8"
      },
      "source": [
        "# Apprentissage avec validation crois√©e\n",
        "y_kfold_pred = model_selection.cross_val_predict(classifier_pipeline, X_train,\n",
        "                                                   y_train, cv=kfold, n_jobs=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wco4qqkjteh8"
      },
      "source": [
        "print(classification_report(y_train, y_kfold_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rw6wuxBvteh8"
      },
      "source": [
        "#### 2.4.2. `StratifiedKFold`\n",
        "\n",
        "`StratifiedKFold` prend en compte la r√©partition des classes, et le pourcentage d'exemples pour chaque classe est pr√©serv√© dans chaque pli."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QygVI58-teh8"
      },
      "source": [
        "stratkfold = model_selection.StratifiedKFold(n_splits=folds, shuffle=True, random_state=12)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdX8lXvqteh8"
      },
      "source": [
        "y_stratkfold_pred = model_selection.cross_val_predict(classifier_pipeline, X_train,\n",
        "                                                   y_train, cv=stratkfold, n_jobs=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUpStKTQteh9"
      },
      "source": [
        "print(classification_report(y_train, y_stratkfold_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KiVwPAA1teh9"
      },
      "source": [
        "**Remarque**\n",
        "\n",
        "Il y a peu de diff√©rences ici entre `KFold` et `StratifiedKFold` car on dispose de suffisamment d'instances et dans les deux cas on m√©lange les donn√©es. D'une mani√®re g√©n√©rale, si les classes ne sont pas √©quilibr√©es, on pr√©f√®rera `StratifiedKFold`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkyoZTFKteh9"
      },
      "source": [
        "### 2.5. Comparaison de plusieurs classifieurs\n",
        "\n",
        "Il est souvent utile de comparer plusieurs algorithmes de classification pour la m√™me t√¢che, afin de d√©terminer lequel fonctionne le mieux.\n",
        "Le choix du classifieur d√©pend de la nature des donn√©es, de la quantit√© disponible, du type de r√©sultat √† obtenir.\n",
        "\n",
        "Pour vous aider dans le choix des classifieurs,  vous pouvez consulter les diagrammes d'aide suivants :\n",
        "\n",
        "<div>\n",
        "<br/>   \n",
        "<img src=\"https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F4138465%2Fde131be0b3fb7d7f9d314e1f6c5f0ee6%2Fml_algos_cheat_sheet.png?generation=1590660360753004&alt=media\" width=\"700\"/>\n",
        "\n",
        "Source : https://www.kaggle.com/getting-started/154432\n",
        "</div>\n",
        "\n",
        "<div>\n",
        "<br/>   \n",
        "<img src=\"https://scikit-learn.org/stable/_static/ml_map.png\" width=\"700\"/>\n",
        "\n",
        "Source : https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXj5q8dIteh-"
      },
      "source": [
        "Nous allons comparer les algorithmes suivants, en utilisant la validation crois√©e :\n",
        "- `DummyClassifier` : baseline, toutes les instances seront class√©es dans la classe la plus fr√©quente (d'autres strat√©gies sont possibles)\n",
        "- `MultinomialNB` : Multinomial Naive Bayes, une des variantes de Naive Bayes g√©n√©ralement utilis√©e pour la classification de textes repr√©sent√©s sous forme de sacs de mots\n",
        "- `DecisionTreeClassifier` : arbre de d√©cision, utilisant l'algorithme CART\n",
        "- `LogisticRegression` : la classe est pr√©dite √† partir d'une combinaison lin√©aire des traits, o√π chaque trait est associ√© √† un coefficient.\n",
        "- `KNeighborsClassifier` : recherche les instances les plus proches dans les donn√©es d'apprentissage afin de d√©terminer la classe.\n",
        "- `RandomForestClassifier` : pr√©diction √† partir d'un ensemble d'arbres de d√©cision al√©atoires, dont les d√©cisions sont agr√©g√©es"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpUWe03Tteh-"
      },
      "source": [
        "<div class=\"alert alert-danger\" role=\"alert\">\n",
        "\n",
        "‚ö†Ô∏è L'ex√©cution de la cellule ci-dessous prend du temps, c'est normal ! ‚ö†Ô∏è\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dKFD8ewteh-"
      },
      "source": [
        "# Mod√®les √† comparer\n",
        "models = [\n",
        "    ('Baseline', DummyClassifier(strategy='most_frequent')),\n",
        "    ('Mutinomial NB', MultinomialNB()),\n",
        "    ('CART', DecisionTreeClassifier()),\n",
        "    ('LR', LogisticRegression()),\n",
        "    ('KNN', KNeighborsClassifier()),\n",
        "    ('Random forest', RandomForestClassifier())\n",
        "]\n",
        "# Evaluation de chaque r√©sultat l'un apr√®s l'autre\n",
        "scores = []\n",
        "names = []\n",
        "scoring = 'macro F1'\n",
        "# Validation crois√©e √† 5 plis\n",
        "kfold = model_selection.StratifiedKFold(n_splits=5, shuffle=True, random_state=12)\n",
        "# It√©ration sur les mod√®les\n",
        "for name, model in models:\n",
        "    # Ajout du nom du mod√®le √† la liste name\n",
        "    names.append(name)\n",
        "    # Cr√©ation de la pipeline pour le mod√®le\n",
        "    model_pipeline = make_pipeline(column_trans, model)\n",
        "    # Validation crois√©e\n",
        "    y_pred = model_selection.cross_val_predict(model_pipeline,\n",
        "                                               X_train, y_train,\n",
        "                                               cv=kfold)\n",
        "    print(name)\n",
        "    print(classification_report(y_train, y_pred))\n",
        "    f1 = metrics.f1_score(y_train, y_pred, average='macro')\n",
        "    scores.append(f1)\n",
        "\n",
        "# Repr√©sentation graphique des r√©sultats\n",
        "indices = np.arange(len(scores))\n",
        "fig = plt.figure()\n",
        "plt.barh(indices, scores, .2, label=\"score\", color='b')\n",
        "plt.yticks(())\n",
        "for i, c in zip(indices, names):\n",
        "    plt.text(-.3, i, c)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ImhGaAhlteh_"
      },
      "source": [
        "<div class=\"alert alert-info\">\n",
        "\n",
        "‚ùì [9] Quel algorithme d'apprentissage obtient les meilleurs r√©sultats (en termes de score F1 macro) ?\n",
        "\n",
        "</div>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class=\"alert alert-info\">\n",
        "\n",
        "‚ùì [10] Pourquoi est-ce que la classe 'Burgundy' est la seule √† obtenir des scores sup√©rieurs √† 0 avec la m√©thode 'Baseline' ?\n",
        "\n",
        "</div>"
      ],
      "metadata": {
        "id": "zslERMFeCHQr"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1X2wzfcJteh_"
      },
      "source": [
        "### 2.6. Entra√Ænement uniquement avec une partie des traits\n",
        "\n",
        "Afin de mieux comprendre l'influence de certains traits sur l'apprentissage, il est d'usage de v√©rifier les r√©sultats en supprimant un trait ou plusieurs traits afin de voir l'influence que cela a sur les r√©sultats.\n",
        "\n",
        "Par exemple, on peut reprendre l'apprentissage en supprimant les traits li√©s aux statistiques textuelles (longueur du texte et nombre de phrases), en ne conservant que les autres traits :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8XY-eS-teh_"
      },
      "source": [
        "column_trans2 = ColumnTransformer(\n",
        "     [\n",
        "         # Colonne 'variety' : bag-of-words\n",
        "         ('variety_bow', var_vectorizer, 'variety'),\n",
        "         # Colonne 'description' : tf-idf\n",
        "         ('description_tfidf', desc_vectorizer, 'description'),\n",
        "     ],\n",
        "     # Colonnes 'expensive' et 'sparkling' : conserv√©es telles quelles\n",
        "     remainder='passthrough'\n",
        " )\n",
        "column_trans2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aohydgivteh_"
      },
      "source": [
        "# Validation crois√©e √† 5 plis\n",
        "for name, model in models:\n",
        "    model_pipeline = make_pipeline(column_trans2, model)\n",
        "    y_pred = model_selection.cross_val_predict(model_pipeline, X_train, y_train,\n",
        "                                               cv=kfold)\n",
        "    print(name)\n",
        "    print(classification_report(y_train, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xbi7LsEteiA"
      },
      "source": [
        "<div class=\"alert alert-info\">\n",
        "\n",
        "‚ùì [11] La suppression des traits li√©s aux statistiques textuelles (longueur du texte et nombre de phrases) a-t-elle un impact positif ou n√©gatif sur les r√©sultats de l'apprentissage ? Qu'en d√©duisez-vous sur l'utilit√© de ces traits pour l'apprentissage ?\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agqd03zEteiA"
      },
      "source": [
        "<div class=\"alert alert-info\">\n",
        "    \n",
        "‚ùì [12] Quels sont les traits les plus importants pour faire la classification selon la r√©gion : 'variety_bow' ou 'description_tfidf' ? (testez l'√©limination de l'un ou l'autre trait, en fixant le param√®tre `remainder='drop'` pour √©liminer les autres colonnes.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWElV7JXteic"
      },
      "source": [
        "## 3. Bonus : Explication des pr√©dictions\n",
        "\n",
        "Nous allons utiliser la biblioth√®que [`lime`](https://github.com/marcotcr/lime/) pour essayer de comprendre les pr√©dictions faites par le mod√®le.\n",
        "\n",
        "L'**explicabilit√©** consiste √† pouvoir expliquer comment un mod√®le aboutit √† ses pr√©dictions, et c'est justement l'objectif de `lime`. `lime` met en √©vidence l'importance de certain tokens du texte pour expliquer la classe pr√©dite pour une instance.\n",
        "\n",
        "Nous allons pour cela prendre le cas de l'apprentissage de la r√©gion de provenance des vins uniquement √† partir de la description."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHsm7qGxteid"
      },
      "source": [
        "c = make_pipeline(desc_vectorizer, LogisticRegression())\n",
        "c.fit(X_train.description, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULljOG02yaJo"
      },
      "source": [
        "! pip install lime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ru7s8wpOteid"
      },
      "source": [
        "from lime.lime_text import LimeTextExplainer\n",
        "class_labels = c.classes_\n",
        "explainer = LimeTextExplainer(class_names=class_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxmVkmBvteid"
      },
      "source": [
        "class_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etMgydZUteie"
      },
      "source": [
        "idx = 5689\n",
        "print(f'Document id : {idx}')\n",
        "print(f'Classe pr√©dite : {c.predict(X_val.loc[[idx]].description)[0]}')\n",
        "print(f'Classe r√©elle : {y_val.loc[idx]}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQHmA0z3teif"
      },
      "source": [
        "exp = explainer.explain_instance(X_val.description.at[idx],\n",
        "                                 c.predict_proba,\n",
        "                                 num_features=6,\n",
        "                                 top_labels=len(class_labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9Zjcl0uteif"
      },
      "source": [
        "print('Explications (tokens qui affectent la classification posititivement et n√©gativement)\\n')\n",
        "for i in range(len(class_labels)):\n",
        "    print(f'Classe {class_labels[i]}')\n",
        "    print('\\n'.join(map(str, exp.as_list(label=i))))\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-Z37fpateig"
      },
      "source": [
        "exp.show_in_notebook(text=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2M4fYW1xteig"
      },
      "source": [
        "exp.show_in_notebook(text=X_val.description.at[idx], labels=(7, 2, 0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzcDXiFIteih"
      },
      "source": [
        "Que se passe-t-il si l'on supprime le mot \"flavors\" du texte d√©crivant le vin ? De combien la probabilit√© de pr√©diction pour la classe \"Loire_Valley\" diminue-t-elle ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8uZex7Kteih"
      },
      "source": [
        "exp = explainer.explain_instance(X_val.description.at[idx].replace('flavors', ''),\n",
        "                                 c.predict_proba,\n",
        "                                 num_features=6,\n",
        "                                 top_labels=len(class_labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ELPsdogteii"
      },
      "source": [
        "exp.show_in_notebook(text=X_val.description.at[idx], labels=(7, 2, 0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mp_4ieadteii"
      },
      "source": [
        "## Sources\n",
        "- http://queirozf.com/entries/scikit-learn-pipeline-examples\n",
        "- http://www.davidsbatista.net/blog/2017/04/01/document_classification/\n",
        "- http://www.pitt.edu/~naraehan/presentation/Movie+Reviews+sentiment+analysis+with+Scikit-Learn.html\n",
        "- http://zacstewart.com/2014/08/05/pipelines-of-featureunions-of-pipelines.html\n",
        "- https://bbengfort.github.io/tutorials/2016/05/19/text-classification-nltk-sckit-learn.html\n",
        "- https://itnext.io/machine-learning-sentiment-analysis-of-movie-reviews-using-logisticregression-62e9622b4532\n",
        "- https://machinelearningmastery.com/compare-machine-learning-algorithms-python-scikit-learn/\n",
        "- https://medium.com/hugo-ferreiras-blog/dealing-with-categorical-features-in-machine-learning-1bb70f07262d\n",
        "- https://ramhiser.com/post/2018-04-16-building-scikit-learn-pipeline-with-pandas-dataframe\n",
        "- https://stackabuse.com/text-classification-with-python-and-scikit-learn/\n",
        "- https://towardsdatascience.com/multi-label-text-classification-with-scikit-learn-30714b7819c5\n",
        "- https://marcotcr.github.io/lime/tutorials/Lime%20-%20multiclass.html"
      ]
    }
  ]
}